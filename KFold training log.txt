---Split 0---
Batch: 0, loss 4.9886.
Batch: 100, loss 2.1528.
Batch: 200, loss 1.8761.
Batch: 300, loss 1.6383.
Batch: 400, loss 1.7804.
Batch: 500, loss 1.3458.
Batch: 600, loss 1.6548.
Batch: 700, loss 1.6249.
Batch: 800, loss 1.2818.
Epoch: 0/1000, training loss: 1.7354, train acc: 0.5058, vali loss: 1.5342, vali acc: 0.5659.
Batch: 0, loss 1.1129.
Batch: 100, loss 1.2184.
Batch: 200, loss 1.1270.
Batch: 300, loss 1.4141.
Batch: 400, loss 1.2849.
Batch: 500, loss 1.1022.
Batch: 600, loss 1.1933.
Batch: 700, loss 1.0839.
Batch: 800, loss 1.0729.
Epoch: 1/1000, training loss: 1.1494, train acc: 0.6434, vali loss: 1.1833, vali acc: 0.6421.
Batch: 0, loss 0.9044.
Batch: 100, loss 0.9586.
Batch: 200, loss 0.8117.
Batch: 300, loss 0.8973.
Batch: 400, loss 0.7853.
Batch: 500, loss 1.0354.
Batch: 600, loss 0.9352.
Batch: 700, loss 0.7746.
Batch: 800, loss 0.7394.
Epoch: 2/1000, training loss: 0.9637, train acc: 0.6928, vali loss: 1.0581, vali acc: 0.6841.
Batch: 0, loss 0.8442.
Batch: 100, loss 0.7598.
Batch: 200, loss 0.6919.
Batch: 300, loss 0.9154.
Batch: 400, loss 1.0581.
Batch: 500, loss 0.7883.
Batch: 600, loss 0.9870.
Batch: 700, loss 0.7755.
Batch: 800, loss 0.6452.
Epoch: 3/1000, training loss: 0.8409, train acc: 0.7259, vali loss: 1.0196, vali acc: 0.6901.
Batch: 0, loss 0.7431.
Batch: 100, loss 0.6602.
Batch: 200, loss 0.5867.
Batch: 300, loss 0.9389.
Batch: 400, loss 0.8010.
Batch: 500, loss 0.8708.
Batch: 600, loss 0.7042.
Batch: 700, loss 0.5713.
Batch: 800, loss 0.6155.
Epoch: 4/1000, training loss: 0.7454, train acc: 0.7516, vali loss: 0.9257, vali acc: 0.7199.
Batch: 0, loss 0.7587.
Batch: 100, loss 0.6887.
Batch: 200, loss 0.8599.
Batch: 300, loss 0.7638.
Batch: 400, loss 0.5527.
Batch: 500, loss 0.7174.
Batch: 600, loss 0.7000.
Batch: 700, loss 0.5523.
Batch: 800, loss 0.6773.
Epoch: 5/1000, training loss: 0.6678, train acc: 0.7736, vali loss: 1.0250, vali acc: 0.6915.
Batch: 0, loss 0.4534.
Batch: 100, loss 0.6783.
Batch: 200, loss 0.4807.
Batch: 300, loss 0.7043.
Batch: 400, loss 0.5262.
Batch: 500, loss 0.6048.
Batch: 600, loss 0.5611.
Batch: 700, loss 0.5365.
Batch: 800, loss 0.5945.
Epoch: 6/1000, training loss: 0.6037, train acc: 0.7941, vali loss: 0.9728, vali acc: 0.7205.
Batch: 0, loss 0.5681.
Batch: 100, loss 0.4719.
Batch: 200, loss 0.6492.
Batch: 300, loss 0.5883.
Batch: 400, loss 0.4707.
Batch: 500, loss 0.5901.
Batch: 600, loss 0.3814.
Batch: 700, loss 0.6384.
Batch: 800, loss 0.5933.
Epoch: 7/1000, training loss: 0.5452, train acc: 0.8125, vali loss: 1.0458, vali acc: 0.7205.
Early stopping
Best epoch: 4, best loss: 0.9257.
---Split 1---
Batch: 0, loss 4.7630.
Batch: 100, loss 2.3589.
Batch: 200, loss 1.5783.
Batch: 300, loss 1.8698.
Batch: 400, loss 1.7056.
Batch: 500, loss 1.4787.
Batch: 600, loss 1.3837.
Batch: 700, loss 1.3743.
Batch: 800, loss 1.4524.
Epoch: 0/1000, training loss: 1.7681, train acc: 0.4994, vali loss: 1.3664, vali acc: 0.5907.
Batch: 0, loss 1.1124.
Batch: 100, loss 1.3351.
Batch: 200, loss 1.2382.
Batch: 300, loss 1.0075.
Batch: 400, loss 1.1159.
Batch: 500, loss 1.0871.
Batch: 600, loss 1.2510.
Batch: 700, loss 0.9979.
Batch: 800, loss 1.1425.
Epoch: 1/1000, training loss: 1.1928, train acc: 0.6327, vali loss: 1.0767, vali acc: 0.6690.
Batch: 0, loss 0.9507.
Batch: 100, loss 1.1626.
Batch: 200, loss 1.0372.
Batch: 300, loss 1.0293.
Batch: 400, loss 0.9775.
Batch: 500, loss 1.1101.
Batch: 600, loss 1.0418.
Batch: 700, loss 1.1038.
Batch: 800, loss 0.8642.
Epoch: 2/1000, training loss: 0.9950, train acc: 0.6837, vali loss: 1.1980, vali acc: 0.6292.
Batch: 0, loss 0.9329.
Batch: 100, loss 0.8867.
Batch: 200, loss 0.9834.
Batch: 300, loss 0.9256.
Batch: 400, loss 0.7175.
Batch: 500, loss 0.8969.
Batch: 600, loss 0.8732.
Batch: 700, loss 0.7663.
Batch: 800, loss 0.8221.
Epoch: 3/1000, training loss: 0.8707, train acc: 0.7171, vali loss: 1.1145, vali acc: 0.6680.
Batch: 0, loss 0.8336.
Batch: 100, loss 0.7719.
Batch: 200, loss 0.9060.
Batch: 300, loss 0.8273.
Batch: 400, loss 0.7936.
Batch: 500, loss 0.7768.
Batch: 600, loss 0.7987.
Batch: 700, loss 0.7030.
Batch: 800, loss 0.8661.
Epoch: 4/1000, training loss: 0.7712, train acc: 0.7445, vali loss: 0.9872, vali acc: 0.7015.
Batch: 0, loss 0.7663.
Batch: 100, loss 0.7684.
Batch: 200, loss 0.7575.
Batch: 300, loss 0.6992.
Batch: 400, loss 0.6976.
Batch: 500, loss 0.6769.
Batch: 600, loss 0.6298.
Batch: 700, loss 0.6404.
Batch: 800, loss 0.6235.
Epoch: 5/1000, training loss: 0.6948, train acc: 0.7664, vali loss: 0.9214, vali acc: 0.7205.
Batch: 0, loss 0.6904.
Batch: 100, loss 0.6909.
Batch: 200, loss 0.5454.
Batch: 300, loss 0.7116.
Batch: 400, loss 0.6107.
Batch: 500, loss 0.6509.
Batch: 600, loss 0.4540.
Batch: 700, loss 0.5234.
Batch: 800, loss 0.6948.
Epoch: 6/1000, training loss: 0.6306, train acc: 0.7861, vali loss: 1.2063, vali acc: 0.6624.
Batch: 0, loss 0.5172.
Batch: 100, loss 0.5957.
Batch: 200, loss 0.4753.
Batch: 300, loss 0.5445.
Batch: 400, loss 0.5353.
Batch: 500, loss 0.4960.
Batch: 600, loss 0.5819.
Batch: 700, loss 0.5273.
Batch: 800, loss 0.4504.
Epoch: 7/1000, training loss: 0.5743, train acc: 0.8027, vali loss: 0.9713, vali acc: 0.7184.
Batch: 0, loss 0.6314.
Batch: 100, loss 0.5260.
Batch: 200, loss 0.5079.
Batch: 300, loss 0.4468.
Batch: 400, loss 0.5772.
Batch: 500, loss 0.3760.
Batch: 600, loss 0.6346.
Batch: 700, loss 0.6874.
Batch: 800, loss 0.5981.
Epoch: 8/1000, training loss: 0.5242, train acc: 0.8191, vali loss: 0.9479, vali acc: 0.7313.
Early stopping
Best epoch: 5, best loss: 0.9214.
---Split 2---
Batch: 0, loss 4.9523.
Batch: 100, loss 2.0714.
Batch: 200, loss 2.0461.
Batch: 300, loss 1.7174.
Batch: 400, loss 1.8699.
Batch: 500, loss 1.4934.
Batch: 600, loss 1.1315.
Batch: 700, loss 1.5295.
Batch: 800, loss 1.4519.
Epoch: 0/1000, training loss: 1.7562, train acc: 0.5001, vali loss: 1.3690, vali acc: 0.5994.
Batch: 0, loss 1.3105.
Batch: 100, loss 1.2727.
Batch: 200, loss 1.3038.
Batch: 300, loss 1.1889.
Batch: 400, loss 1.0298.
Batch: 500, loss 1.1246.
Batch: 600, loss 0.9725.
Batch: 700, loss 1.2145.
Batch: 800, loss 1.2358.
Epoch: 1/1000, training loss: 1.1721, train acc: 0.6368, vali loss: 1.1501, vali acc: 0.6551.
Batch: 0, loss 1.0975.
Batch: 100, loss 1.0192.
Batch: 200, loss 1.0715.
Batch: 300, loss 1.0091.
Batch: 400, loss 1.0465.
Batch: 500, loss 0.7844.
Batch: 600, loss 0.9997.
Batch: 700, loss 1.1490.
Batch: 800, loss 0.8545.
Epoch: 2/1000, training loss: 0.9746, train acc: 0.6884, vali loss: 1.0875, vali acc: 0.6667.
Batch: 0, loss 0.8589.
Batch: 100, loss 0.7426.
Batch: 200, loss 0.8768.
Batch: 300, loss 0.7643.
Batch: 400, loss 0.9576.
Batch: 500, loss 0.7732.
Batch: 600, loss 0.8451.
Batch: 700, loss 0.7385.
Batch: 800, loss 0.8311.
Epoch: 3/1000, training loss: 0.8512, train acc: 0.7231, vali loss: 1.0557, vali acc: 0.6801.
Batch: 0, loss 0.7570.
Batch: 100, loss 0.7524.
Batch: 200, loss 0.7481.
Batch: 300, loss 0.9089.
Batch: 400, loss 0.8277.
Batch: 500, loss 0.6506.
Batch: 600, loss 0.8389.
Batch: 700, loss 0.7467.
Batch: 800, loss 0.6396.
Epoch: 4/1000, training loss: 0.7542, train acc: 0.7490, vali loss: 0.9933, vali acc: 0.6980.
Batch: 0, loss 0.6545.
Batch: 100, loss 0.7241.
Batch: 200, loss 0.7665.
Batch: 300, loss 0.6895.
Batch: 400, loss 0.7057.
Batch: 500, loss 0.6360.
Batch: 600, loss 0.7223.
Batch: 700, loss 0.8797.
Batch: 800, loss 0.5530.
Epoch: 5/1000, training loss: 0.6772, train acc: 0.7700, vali loss: 0.9490, vali acc: 0.7300.
Batch: 0, loss 0.4679.
Batch: 100, loss 0.6649.
Batch: 200, loss 0.6743.
Batch: 300, loss 0.6049.
Batch: 400, loss 0.5924.
Batch: 500, loss 0.8438.
Batch: 600, loss 0.6456.
Batch: 700, loss 0.5732.
Batch: 800, loss 0.6708.
Epoch: 6/1000, training loss: 0.6151, train acc: 0.7900, vali loss: 1.0537, vali acc: 0.7033.
Batch: 0, loss 0.5354.
Batch: 100, loss 0.4804.
Batch: 200, loss 0.6375.
Batch: 300, loss 0.4929.
Batch: 400, loss 0.5216.
Batch: 500, loss 0.5510.
Batch: 600, loss 0.6327.
Batch: 700, loss 0.4742.
Batch: 800, loss 0.5608.
Epoch: 7/1000, training loss: 0.5572, train acc: 0.8091, vali loss: 0.9599, vali acc: 0.7207.
Batch: 0, loss 0.4941.
Batch: 100, loss 0.4365.
Batch: 200, loss 0.3759.
Batch: 300, loss 0.5858.
Batch: 400, loss 0.4839.
Batch: 500, loss 0.4556.
Batch: 600, loss 0.4313.
Batch: 700, loss 0.3306.
Batch: 800, loss 0.6902.
Epoch: 8/1000, training loss: 0.5078, train acc: 0.8240, vali loss: 1.0674, vali acc: 0.7044.
Early stopping
Best epoch: 5, best loss: 0.9490.
---Split 3---
Batch: 0, loss 4.8763.
Batch: 100, loss 2.2694.
Batch: 200, loss 1.8056.
Batch: 300, loss 1.8721.
Batch: 400, loss 1.4624.
Batch: 500, loss 1.5919.
Batch: 600, loss 1.5928.
Batch: 700, loss 1.4077.
Batch: 800, loss 1.5707.
Epoch: 0/1000, training loss: 1.7405, train acc: 0.5035, vali loss: 1.3350, vali acc: 0.6023.
Batch: 0, loss 1.2342.
Batch: 100, loss 1.3817.
Batch: 200, loss 1.1840.
Batch: 300, loss 1.2434.
Batch: 400, loss 1.1814.
Batch: 500, loss 1.0604.
Batch: 600, loss 1.1578.
Batch: 700, loss 1.0692.
Batch: 800, loss 1.0629.
Epoch: 1/1000, training loss: 1.1706, train acc: 0.6365, vali loss: 1.1763, vali acc: 0.6384.
Batch: 0, loss 1.0897.
Batch: 100, loss 0.9561.
Batch: 200, loss 0.9304.
Batch: 300, loss 0.8409.
Batch: 400, loss 0.9646.
Batch: 500, loss 0.9314.
Batch: 600, loss 1.0334.
Batch: 700, loss 0.9733.
Batch: 800, loss 0.8531.
Epoch: 2/1000, training loss: 0.9710, train acc: 0.6900, vali loss: 0.9996, vali acc: 0.6915.
Batch: 0, loss 0.7882.
Batch: 100, loss 0.8894.
Batch: 200, loss 0.7513.
Batch: 300, loss 1.1432.
Batch: 400, loss 1.1094.
Batch: 500, loss 0.8307.
Batch: 600, loss 0.6921.
Batch: 700, loss 0.8575.
Batch: 800, loss 0.8582.
Epoch: 3/1000, training loss: 0.8516, train acc: 0.7213, vali loss: 1.0699, vali acc: 0.6754.
Batch: 0, loss 0.7539.
Batch: 100, loss 0.7451.
Batch: 200, loss 0.8579.
Batch: 300, loss 0.8906.
Batch: 400, loss 0.6509.
Batch: 500, loss 0.7152.
Batch: 600, loss 0.7182.
Batch: 700, loss 0.7585.
Batch: 800, loss 0.7177.
Epoch: 4/1000, training loss: 0.7550, train acc: 0.7481, vali loss: 0.9361, vali acc: 0.7128.
Batch: 0, loss 0.7549.
Batch: 100, loss 0.6656.
Batch: 200, loss 0.6356.
Batch: 300, loss 0.6268.
Batch: 400, loss 0.6306.
Batch: 500, loss 0.5095.
Batch: 600, loss 0.7816.
Batch: 700, loss 0.6070.
Batch: 800, loss 0.8376.
Epoch: 5/1000, training loss: 0.6815, train acc: 0.7704, vali loss: 0.8950, vali acc: 0.7278.
Batch: 0, loss 0.5912.
Batch: 100, loss 0.4855.
Batch: 200, loss 0.5779.
Batch: 300, loss 0.6343.
Batch: 400, loss 0.5072.
Batch: 500, loss 0.6532.
Batch: 600, loss 0.6802.
Batch: 700, loss 0.4899.
Batch: 800, loss 0.5163.
Epoch: 6/1000, training loss: 0.6156, train acc: 0.7900, vali loss: 0.9365, vali acc: 0.7205.
Batch: 0, loss 0.5269.
Batch: 100, loss 0.5883.
Batch: 200, loss 0.4496.
Batch: 300, loss 0.4553.
Batch: 400, loss 0.4142.
Batch: 500, loss 0.6157.
Batch: 600, loss 0.4951.
Batch: 700, loss 0.4912.
Batch: 800, loss 0.6029.
Epoch: 7/1000, training loss: 0.5597, train acc: 0.8075, vali loss: 1.0749, vali acc: 0.7015.
Batch: 0, loss 0.4293.
Batch: 100, loss 0.5890.
Batch: 200, loss 0.3790.
Batch: 300, loss 0.4955.
Batch: 400, loss 0.8376.
Batch: 500, loss 0.5008.
Batch: 600, loss 0.5480.
Batch: 700, loss 0.5721.
Batch: 800, loss 0.5131.
Epoch: 8/1000, training loss: 0.5098, train acc: 0.8245, vali loss: 0.9126, vali acc: 0.7408.
Early stopping
Best epoch: 5, best loss: 0.8950.
---Split 4---
Batch: 0, loss 4.8619.
Batch: 100, loss 2.1674.
Batch: 200, loss 1.9738.
Batch: 300, loss 1.7568.
Batch: 400, loss 1.5636.
Batch: 500, loss 1.5295.
Batch: 600, loss 1.2196.
Batch: 700, loss 1.4183.
Batch: 800, loss 1.2278.
Epoch: 0/1000, training loss: 1.7558, train acc: 0.5016, vali loss: 1.7267, vali acc: 0.4971.
Batch: 0, loss 1.1972.
Batch: 100, loss 1.2230.
Batch: 200, loss 1.2241.
Batch: 300, loss 1.3054.
Batch: 400, loss 1.1826.
Batch: 500, loss 1.0920.
Batch: 600, loss 1.3035.
Batch: 700, loss 1.0028.
Batch: 800, loss 0.9049.
Epoch: 1/1000, training loss: 1.1752, train acc: 0.6362, vali loss: 1.1005, vali acc: 0.6648.
Batch: 0, loss 1.0488.
Batch: 100, loss 0.8642.
Batch: 200, loss 0.9875.
Batch: 300, loss 0.9903.
Batch: 400, loss 1.0215.
Batch: 500, loss 0.8411.
Batch: 600, loss 0.9164.
Batch: 700, loss 1.0173.
Batch: 800, loss 1.2585.
Epoch: 2/1000, training loss: 0.9794, train acc: 0.6869, vali loss: 1.0523, vali acc: 0.6756.
Batch: 0, loss 0.8295.
Batch: 100, loss 1.0328.
Batch: 200, loss 0.6953.
Batch: 300, loss 1.0124.
Batch: 400, loss 0.8149.
Batch: 500, loss 0.8798.
Batch: 600, loss 0.7965.
Batch: 700, loss 0.7126.
Batch: 800, loss 0.8593.
Epoch: 3/1000, training loss: 0.8524, train acc: 0.7220, vali loss: 0.9589, vali acc: 0.7039.
Batch: 0, loss 0.6719.
Batch: 100, loss 0.7726.
Batch: 200, loss 0.9027.
Batch: 300, loss 0.8979.
Batch: 400, loss 0.7557.
Batch: 500, loss 0.7525.
Batch: 600, loss 0.8044.
Batch: 700, loss 0.6425.
Batch: 800, loss 0.6689.
Epoch: 4/1000, training loss: 0.7556, train acc: 0.7495, vali loss: 0.9625, vali acc: 0.7097.
Batch: 0, loss 0.6644.
Batch: 100, loss 0.4412.
Batch: 200, loss 0.7229.
Batch: 300, loss 0.7349.
Batch: 400, loss 0.7355.
Batch: 500, loss 0.7082.
Batch: 600, loss 0.7496.
Batch: 700, loss 0.5763.
Batch: 800, loss 0.5517.
Epoch: 5/1000, training loss: 0.6794, train acc: 0.7699, vali loss: 0.9968, vali acc: 0.7075.
Batch: 0, loss 0.5902.
Batch: 100, loss 0.6805.
Batch: 200, loss 0.6265.
Batch: 300, loss 0.5623.
Batch: 400, loss 0.5559.
Batch: 500, loss 0.7551.
Batch: 600, loss 0.5492.
Batch: 700, loss 0.6266.
Batch: 800, loss 0.4548.
Epoch: 6/1000, training loss: 0.6172, train acc: 0.7898, vali loss: 0.9139, vali acc: 0.7300.
Batch: 0, loss 0.4955.
Batch: 100, loss 0.6300.
Batch: 200, loss 0.5960.
Batch: 300, loss 0.5584.
Batch: 400, loss 0.5717.
Batch: 500, loss 0.6005.
Batch: 600, loss 0.5565.
Batch: 700, loss 0.5076.
Batch: 800, loss 0.6103.
Epoch: 7/1000, training loss: 0.5607, train acc: 0.8082, vali loss: 0.9017, vali acc: 0.7416.
Batch: 0, loss 0.5783.
Batch: 100, loss 0.3177.
Batch: 200, loss 0.5224.
Batch: 300, loss 0.5681.
Batch: 400, loss 0.5467.
Batch: 500, loss 0.5468.
Batch: 600, loss 0.4862.
Batch: 700, loss 0.4287.
Batch: 800, loss 0.6338.
Epoch: 8/1000, training loss: 0.5073, train acc: 0.8248, vali loss: 1.1050, vali acc: 0.6983.
Batch: 0, loss 0.6078.
Batch: 100, loss 0.4300.
Batch: 200, loss 0.4061.
Batch: 300, loss 0.4604.
Batch: 400, loss 0.6103.
Batch: 500, loss 0.5242.
Batch: 600, loss 0.5541.
Batch: 700, loss 0.4087.
Batch: 800, loss 0.5460.
Epoch: 9/1000, training loss: 0.4641, train acc: 0.8390, vali loss: 1.0766, vali acc: 0.7104.
Batch: 0, loss 0.3861.
Batch: 100, loss 0.3673.
Batch: 200, loss 0.3623.
Batch: 300, loss 0.3561.
Batch: 400, loss 0.4328.
Batch: 500, loss 0.4135.
Batch: 600, loss 0.5867.
Batch: 700, loss 0.4636.
Batch: 800, loss 0.4181.
Epoch: 10/1000, training loss: 0.4283, train acc: 0.8513, vali loss: 1.0792, vali acc: 0.7178.
Early stopping
Best epoch: 7, best loss: 0.9017.
---Split 5---
Batch: 0, loss 4.9843.
Batch: 100, loss 2.2985.
Batch: 200, loss 2.0585.
Batch: 300, loss 1.7248.
Batch: 400, loss 1.6019.
Batch: 500, loss 1.6213.
Batch: 600, loss 1.6168.
Batch: 700, loss 1.2218.
Batch: 800, loss 1.2675.
Epoch: 0/1000, training loss: 1.7684, train acc: 0.4964, vali loss: 1.5213, vali acc: 0.5512.
Batch: 0, loss 1.2820.
Batch: 100, loss 1.1705.
Batch: 200, loss 0.9229.
Batch: 300, loss 1.1193.
Batch: 400, loss 0.9069.
Batch: 500, loss 1.1754.
Batch: 600, loss 1.1214.
Batch: 700, loss 1.2662.
Batch: 800, loss 1.1150.
Epoch: 1/1000, training loss: 1.1743, train acc: 0.6355, vali loss: 1.1283, vali acc: 0.6527.
Batch: 0, loss 1.0079.
Batch: 100, loss 1.0701.
Batch: 200, loss 1.0171.
Batch: 300, loss 0.9771.
Batch: 400, loss 0.8377.
Batch: 500, loss 0.9367.
Batch: 600, loss 0.9269.
Batch: 700, loss 0.9929.
Batch: 800, loss 0.9210.
Epoch: 2/1000, training loss: 0.9844, train acc: 0.6859, vali loss: 1.1480, vali acc: 0.6522.
Batch: 0, loss 0.7574.
Batch: 100, loss 1.0031.
Batch: 200, loss 0.7335.
Batch: 300, loss 0.6547.
Batch: 400, loss 0.7976.
Batch: 500, loss 0.9568.
Batch: 600, loss 0.7041.
Batch: 700, loss 0.7547.
Batch: 800, loss 0.8476.
Epoch: 3/1000, training loss: 0.8549, train acc: 0.7208, vali loss: 1.0340, vali acc: 0.6988.
Batch: 0, loss 0.7294.
Batch: 100, loss 0.8369.
Batch: 200, loss 0.5988.
Batch: 300, loss 0.6625.
Batch: 400, loss 0.6911.
Batch: 500, loss 0.7978.
Batch: 600, loss 0.7437.
Batch: 700, loss 0.7715.
Batch: 800, loss 0.9222.
Epoch: 4/1000, training loss: 0.7662, train acc: 0.7462, vali loss: 0.9219, vali acc: 0.7160.
Batch: 0, loss 0.6843.
Batch: 100, loss 0.8004.
Batch: 200, loss 0.7229.
Batch: 300, loss 0.7523.
Batch: 400, loss 0.7398.
Batch: 500, loss 0.7060.
Batch: 600, loss 0.7812.
Batch: 700, loss 0.6320.
Batch: 800, loss 0.6566.
Epoch: 5/1000, training loss: 0.6878, train acc: 0.7684, vali loss: 0.9863, vali acc: 0.7104.
Batch: 0, loss 0.6604.
Batch: 100, loss 0.6026.
Batch: 200, loss 0.6787.
Batch: 300, loss 0.6762.
Batch: 400, loss 0.5338.
Batch: 500, loss 0.5909.
Batch: 600, loss 0.7583.
Batch: 700, loss 0.7992.
Batch: 800, loss 0.6439.
Epoch: 6/1000, training loss: 0.6217, train acc: 0.7867, vali loss: 0.9510, vali acc: 0.7120.
Batch: 0, loss 0.5283.
Batch: 100, loss 0.5703.
Batch: 200, loss 0.4898.
Batch: 300, loss 0.6824.
Batch: 400, loss 0.6223.
Batch: 500, loss 0.7742.
Batch: 600, loss 0.5033.
Batch: 700, loss 0.7072.
Batch: 800, loss 0.5184.
Epoch: 7/1000, training loss: 0.5652, train acc: 0.8046, vali loss: 1.0422, vali acc: 0.7031.
Early stopping
Best epoch: 4, best loss: 0.9219.
---Split 6---
Batch: 0, loss 4.8569.
Batch: 100, loss 2.0953.
Batch: 200, loss 1.7975.
Batch: 300, loss 1.6764.
Batch: 400, loss 1.4507.
Batch: 500, loss 1.5780.
Batch: 600, loss 1.2776.
Batch: 700, loss 1.2590.
Batch: 800, loss 1.3733.
Epoch: 0/1000, training loss: 1.7121, train acc: 0.5111, vali loss: 1.3707, vali acc: 0.5939.
Batch: 0, loss 1.1210.
Batch: 100, loss 1.3147.
Batch: 200, loss 1.0053.
Batch: 300, loss 0.9755.
Batch: 400, loss 1.0295.
Batch: 500, loss 1.1491.
Batch: 600, loss 1.1079.
Batch: 700, loss 0.9533.
Batch: 800, loss 1.2054.
Epoch: 1/1000, training loss: 1.1470, train acc: 0.6427, vali loss: 1.2365, vali acc: 0.6324.
Batch: 0, loss 1.0588.
Batch: 100, loss 0.8541.
Batch: 200, loss 0.8580.
Batch: 300, loss 0.9394.
Batch: 400, loss 0.9666.
Batch: 500, loss 1.0383.
Batch: 600, loss 1.0724.
Batch: 700, loss 1.1589.
Batch: 800, loss 0.9461.
Epoch: 2/1000, training loss: 0.9655, train acc: 0.6909, vali loss: 1.0639, vali acc: 0.6825.
Batch: 0, loss 0.8129.
Batch: 100, loss 0.8787.
Batch: 200, loss 0.8250.
Batch: 300, loss 0.9019.
Batch: 400, loss 0.7674.
Batch: 500, loss 0.5821.
Batch: 600, loss 0.8524.
Batch: 700, loss 0.7445.
Batch: 800, loss 0.9135.
Epoch: 3/1000, training loss: 0.8436, train acc: 0.7243, vali loss: 0.9863, vali acc: 0.7049.
Batch: 0, loss 0.9354.
Batch: 100, loss 0.8317.
Batch: 200, loss 0.7240.
Batch: 300, loss 0.7471.
Batch: 400, loss 0.8717.
Batch: 500, loss 0.6992.
Batch: 600, loss 0.7385.
Batch: 700, loss 0.7152.
Batch: 800, loss 0.6601.
Epoch: 4/1000, training loss: 0.7508, train acc: 0.7493, vali loss: 0.9734, vali acc: 0.7078.
Batch: 0, loss 0.6533.
Batch: 100, loss 0.6446.
Batch: 200, loss 0.6360.
Batch: 300, loss 0.5121.
Batch: 400, loss 0.6007.
Batch: 500, loss 0.6890.
Batch: 600, loss 0.7954.
Batch: 700, loss 0.5248.
Batch: 800, loss 0.7520.
Epoch: 5/1000, training loss: 0.6750, train acc: 0.7728, vali loss: 1.0288, vali acc: 0.7007.
Batch: 0, loss 0.7255.
Batch: 100, loss 0.5603.
Batch: 200, loss 0.5649.
Batch: 300, loss 0.7134.
Batch: 400, loss 0.7360.
Batch: 500, loss 0.8189.
Batch: 600, loss 0.6249.
Batch: 700, loss 0.6741.
Batch: 800, loss 0.5423.
Epoch: 6/1000, training loss: 0.6128, train acc: 0.7901, vali loss: 0.9978, vali acc: 0.7139.
Batch: 0, loss 0.4830.
Batch: 100, loss 0.4977.
Batch: 200, loss 0.4856.
Batch: 300, loss 0.5815.
Batch: 400, loss 0.5182.
Batch: 500, loss 0.6285.
Batch: 600, loss 0.6209.
Batch: 700, loss 0.5377.
Batch: 800, loss 0.6383.
Epoch: 7/1000, training loss: 0.5577, train acc: 0.8076, vali loss: 1.1453, vali acc: 0.6907.
Early stopping
Best epoch: 4, best loss: 0.9734.
---Split 7---
Batch: 0, loss 4.9024.
Batch: 100, loss 2.2514.
Batch: 200, loss 1.9347.
Batch: 300, loss 1.5940.
Batch: 400, loss 1.4932.
Batch: 500, loss 1.4912.
Batch: 600, loss 1.2719.
Batch: 700, loss 1.3211.
Batch: 800, loss 1.2486.
Epoch: 0/1000, training loss: 1.7352, train acc: 0.5040, vali loss: 1.5272, vali acc: 0.5551.
Batch: 0, loss 1.6019.
Batch: 100, loss 1.2099.
Batch: 200, loss 1.2765.
Batch: 300, loss 1.2460.
Batch: 400, loss 1.2556.
Batch: 500, loss 1.1502.
Batch: 600, loss 1.1380.
Batch: 700, loss 0.9239.
Batch: 800, loss 1.1456.
Epoch: 1/1000, training loss: 1.1565, train acc: 0.6408, vali loss: 1.1666, vali acc: 0.6374.
Batch: 0, loss 1.0955.
Batch: 100, loss 1.0071.
Batch: 200, loss 1.0726.
Batch: 300, loss 1.0483.
Batch: 400, loss 1.2924.
Batch: 500, loss 0.9590.
Batch: 600, loss 0.9649.
Batch: 700, loss 0.8722.
Batch: 800, loss 0.9659.
Epoch: 2/1000, training loss: 0.9643, train acc: 0.6912, vali loss: 1.0063, vali acc: 0.6893.
Batch: 0, loss 0.9147.
Batch: 100, loss 0.7782.
Batch: 200, loss 0.7746.
Batch: 300, loss 0.8472.
Batch: 400, loss 0.8441.
Batch: 500, loss 0.9210.
Batch: 600, loss 0.8535.
Batch: 700, loss 1.0562.
Batch: 800, loss 0.7239.
Epoch: 3/1000, training loss: 0.8425, train acc: 0.7255, vali loss: 0.9364, vali acc: 0.7155.
Batch: 0, loss 0.8592.
Batch: 100, loss 0.6353.
Batch: 200, loss 0.8520.
Batch: 300, loss 0.6711.
Batch: 400, loss 0.9594.
Batch: 500, loss 0.9082.
Batch: 600, loss 0.6129.
Batch: 700, loss 0.8448.
Batch: 800, loss 0.7029.
Epoch: 4/1000, training loss: 0.7529, train acc: 0.7502, vali loss: 1.0005, vali acc: 0.7017.
Batch: 0, loss 0.7116.
Batch: 100, loss 0.5061.
Batch: 200, loss 0.5750.
Batch: 300, loss 0.7105.
Batch: 400, loss 0.6612.
Batch: 500, loss 0.5684.
Batch: 600, loss 0.6087.
Batch: 700, loss 0.7983.
Batch: 800, loss 0.7724.
Epoch: 5/1000, training loss: 0.6746, train acc: 0.7725, vali loss: 0.9142, vali acc: 0.7294.
Batch: 0, loss 0.7205.
Batch: 100, loss 0.4278.
Batch: 200, loss 0.6821.
Batch: 300, loss 0.5423.
Batch: 400, loss 0.6197.
Batch: 500, loss 0.6309.
Batch: 600, loss 0.5675.
Batch: 700, loss 0.5712.
Batch: 800, loss 0.5834.
Epoch: 6/1000, training loss: 0.6136, train acc: 0.7902, vali loss: 0.9186, vali acc: 0.7260.
Batch: 0, loss 0.6344.
Batch: 100, loss 0.5735.
Batch: 200, loss 0.5077.
Batch: 300, loss 0.6160.
Batch: 400, loss 0.6599.
Batch: 500, loss 0.5002.
Batch: 600, loss 0.4555.
Batch: 700, loss 0.6251.
Batch: 800, loss 0.5459.
Epoch: 7/1000, training loss: 0.5552, train acc: 0.8091, vali loss: 1.0198, vali acc: 0.7068.
Batch: 0, loss 0.5222.
Batch: 100, loss 0.4529.
Batch: 200, loss 0.5419.
Batch: 300, loss 0.6440.
Batch: 400, loss 0.6341.
Batch: 500, loss 0.5795.
Batch: 600, loss 0.5376.
Batch: 700, loss 0.7642.
Batch: 800, loss 0.4770.
Epoch: 8/1000, training loss: 0.5102, train acc: 0.8246, vali loss: 0.9675, vali acc: 0.7249.
Early stopping
Best epoch: 5, best loss: 0.9142.